{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis : Baysian\n",
    "\n",
    "_deeplearning.ai/Natural Language Processing Specialization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_tweets = twitter_samples.strings(\"positive_tweets.json\")\n",
    "all_neg_tweets = twitter_samples.strings(\"negative_tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tw in all_pos_tweets:\n",
    "#     result = re.match(r'Rettweet|(R|r)(T|t)[\\s]+',tw)\n",
    "#     if result:\n",
    "#         print(tw)\n",
    "#         print('*'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.array(all_pos_tweets),np.array(all_pos_tweets)))\n",
    "y = np.hstack((np.zeros(len(all_pos_tweets)),np.ones(len(all_neg_tweets))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import string\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \n",
    "    stopwords_ = stopwords.words('english')\n",
    "    # remove stock market ticker\n",
    "    tweet = re.sub(r'\\$\\w*','',tweet)\n",
    "    # remove RT\n",
    "    tweet = re.sub(r'^Rettweet|^(R|r)(T|t)[\\s]+','',tweet)\n",
    "    # remove hyperlink\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtag\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case = False, strip_handles = True, reduce_len = True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    tweets_clean = []\n",
    "    \n",
    "    for word in tweet_tokens:\n",
    "        if word not in stopwords_ and word not in string.punctuation:\n",
    "            stem_word = PorterStemmer().stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'great', 'day', ':)', 'good', 'morn']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "\n",
    "process_tweet(custom_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"BASE,itemA,itemB,Central California\\r\\n\"\n",
    "# re.findall(r'([^,]+)(?:,|\\r\\n)', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Hello World\"\n",
    "#re.findall(r'([^,]+)', s) # ['Hello world]\n",
    "#re.findall(r'([^,]+)(?:\\s)', s) # ['Hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freqs(tweets,class_):\n",
    "    freq_dict = {}\n",
    "    if isinstance(tweets,np.ndarray):\n",
    "        tweets = tweets.tolist()\n",
    "    if isinstance(class_,np.ndarray):\n",
    "        class_ = class_.tolist()\n",
    "    for tweet,c in zip(tweets,class_):\n",
    "        for word in process_tweet(tweet):\n",
    "            if (word,c) not in freq_dict:\n",
    "                freq_dict[(word,c)] = 1\n",
    "            else:\n",
    "                freq_dict[(word,c)] += 1\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "tweets = np.array(['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired'])\n",
    "ys = np.array([1, 0, 0, 0, 0])\n",
    "word_freqs(tweets, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pairs</th>\n",
       "      <th>Frequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(friday, 1.0)</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(:), 1.0)</td>\n",
       "      <td>2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(good, 0.0)</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(thank, 0.0)</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(anyway, 0.0)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pairs  Frequence\n",
       "0  (friday, 1.0)         91\n",
       "1      (:), 1.0)       2891\n",
       "2    (good, 0.0)        195\n",
       "3   (thank, 0.0)        464\n",
       "4  (anyway, 0.0)         13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = word_freqs(X_train,y_train)\n",
    "freq_dict = pd.DataFrame({'Pairs': list(freqs.keys()), 'Frequence': list(freqs.values())})\n",
    "freq_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the freq table like the lecture note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pairs</th>\n",
       "      <th>Frequence</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(friday, 1.0)</td>\n",
       "      <td>91</td>\n",
       "      <td>friday</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(:), 1.0)</td>\n",
       "      <td>2891</td>\n",
       "      <td>:)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(good, 0.0)</td>\n",
       "      <td>195</td>\n",
       "      <td>good</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(thank, 0.0)</td>\n",
       "      <td>464</td>\n",
       "      <td>thank</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(anyway, 0.0)</td>\n",
       "      <td>13</td>\n",
       "      <td>anyway</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>(unreal, 1.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>unreal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>(zain, 1.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>zain</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>(zac, 1.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>zac</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>(isaac, 1.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>isaac</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11520</th>\n",
       "      <td>(oss, 1.0)</td>\n",
       "      <td>1</td>\n",
       "      <td>oss</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11521 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pairs  Frequence Vocabulary  Class\n",
       "0      (friday, 1.0)         91     friday    1.0\n",
       "1          (:), 1.0)       2891         :)    1.0\n",
       "2        (good, 0.0)        195       good    0.0\n",
       "3       (thank, 0.0)        464      thank    0.0\n",
       "4      (anyway, 0.0)         13     anyway    0.0\n",
       "...              ...        ...        ...    ...\n",
       "11516  (unreal, 1.0)          1     unreal    1.0\n",
       "11517    (zain, 1.0)          1       zain    1.0\n",
       "11518     (zac, 1.0)          1        zac    1.0\n",
       "11519   (isaac, 1.0)          1      isaac    1.0\n",
       "11520     (oss, 1.0)          1        oss    1.0\n",
       "\n",
       "[11521 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = freq_dict.copy()\n",
    "word_freq[\"Vocabulary\"] = word_freq[\"Pairs\"].apply(lambda x : x[0])\n",
    "word_freq[\"Class\"] = word_freq[\"Pairs\"].apply(lambda x : x[1])\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = list(set(list(word_freq.Vocabulary.values)))\n",
    "freq_dict_info = pd.DataFrame(columns = [\"Vocabulary\",\"PosFreq(1)\",\"NegFreq(0)\"])\n",
    "\n",
    "for w in key_words:\n",
    "    pos_freq = freqs.get((w,1.0),0)\n",
    "    neg_freq = freqs.get((w,0.0),0)\n",
    "    freq_dict_info = freq_dict_info.append({\"Vocabulary\": w, \"PosFreq(1)\" : pos_freq,\"NegFreq(0)\":neg_freq},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>PosFreq(1)</th>\n",
       "      <th>NegFreq(0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>(-:</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>(:</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>):</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>---&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>--&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>🚂</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>🚮</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>🚲</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>󾌴</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>󾰀</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6432 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vocabulary PosFreq(1) NegFreq(0)\n",
       "4413        (-:          2          2\n",
       "328          (:          0          1\n",
       "1932         ):          5          5\n",
       "3152       --->          1          0\n",
       "151         -->          2          2\n",
       "...         ...        ...        ...\n",
       "6357          🚂          0          1\n",
       "253           🚮          1          1\n",
       "6306          🚲          2          2\n",
       "6096          󾌴          1          0\n",
       "1616          󾰀          1          1\n",
       "\n",
       "[6432 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict_info = freq_dict_info.sort_values(['Vocabulary'])\n",
    "freq_dict_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>PosFreq(1)</th>\n",
       "      <th>NegFreq(0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>laid</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>maxfreshmov</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>mayhem</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>mb</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>mba</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>love</td>\n",
       "      <td>313</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>:D</td>\n",
       "      <td>504</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>thank</td>\n",
       "      <td>505</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>:-)</td>\n",
       "      <td>532</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>:)</td>\n",
       "      <td>2891</td>\n",
       "      <td>2851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6432 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vocabulary PosFreq(1) NegFreq(0)\n",
       "2230         laid          0          2\n",
       "1471  maxfreshmov          0          2\n",
       "4022       mayhem          0          1\n",
       "671            mb          0          1\n",
       "3955          mba          0          1\n",
       "...           ...        ...        ...\n",
       "4006         love        313        325\n",
       "2558           :D        504        471\n",
       "2191        thank        505        464\n",
       "3923          :-)        532        560\n",
       "146            :)       2891       2851\n",
       "\n",
       "[6432 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict_info.sort_values([\"PosFreq(1)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5752, 5769)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_pos = len(freq_dict_info[freq_dict_info['PosFreq(1)'] > 0])\n",
    "V_neg = len(freq_dict_info[freq_dict_info['NegFreq(0)'] > 0])\n",
    "V_pos,V_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laplacian smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V} $$\n",
    "\n",
    "- the total number of positive words and total number of negative words $N_{pos}$ and $N_{neg}$.\n",
    "- the total number of unique positive words, $V_{pos}$, and total <strong>unique</strong> negative words $V_{neg}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict_info[\"Prob_pos\"] = (freq_dict_info[\"PosFreq(1)\"] + 1) / (np.sum(freq_dict_info[\"PosFreq(1)\"]) + V_pos)\n",
    "freq_dict_info[\"Prob_neg\"] = (freq_dict_info[\"NegFreq(0)\"] + 1) / (np.sum(freq_dict_info[\"NegFreq(0)\"]) + V_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>PosFreq(1)</th>\n",
       "      <th>NegFreq(0)</th>\n",
       "      <th>Prob_pos</th>\n",
       "      <th>Prob_neg</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>(-:</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.994793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>(:</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.497397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>):</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.994793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>---&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.989586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>--&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.994793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>🚂</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.497397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>🚮</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.994793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>🚲</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.994793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>󾌴</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.989586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>󾰀</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.994793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6432 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vocabulary PosFreq(1) NegFreq(0)  Prob_pos  Prob_neg     ratio\n",
       "4413        (-:          2          2  0.000091  0.000092  0.994793\n",
       "328          (:          0          1   0.00003  0.000061  0.497397\n",
       "1932         ):          5          5  0.000183  0.000184  0.994793\n",
       "3152       --->          1          0  0.000061  0.000031  1.989586\n",
       "151         -->          2          2  0.000091  0.000092  0.994793\n",
       "...         ...        ...        ...       ...       ...       ...\n",
       "6357          🚂          0          1   0.00003  0.000061  0.497397\n",
       "253           🚮          1          1  0.000061  0.000061  0.994793\n",
       "6306          🚲          2          2  0.000091  0.000092  0.994793\n",
       "6096          󾌴          1          0  0.000061  0.000031  1.989586\n",
       "1616          󾰀          1          1  0.000061  0.000061  0.994793\n",
       "\n",
       "[6432 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict_info[\"ratio\"] = freq_dict_info[\"Prob_pos\"] / freq_dict_info[\"Prob_neg\"] \n",
    "freq_dict_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(freq_dict_info.Prob_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_pos_tweet = np.sum(y_train)\n",
    "N_neg_tweet = len(y_train) - np.sum(y_train)\n",
    "Prob_pos_tweet = N_pos_tweet / len(y_train)\n",
    "Prob_neg_tweet = N_neg_tweet / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prob_pos_tweet + Prob_neg_tweet == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p = logprior + \\sum_i^N (loglikelihood_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet,logprior,df):\n",
    "    words = process_tweet(tweet)\n",
    "    p = 0\n",
    "    p += logprior\n",
    "    for word in words:\n",
    "        if word in df.Vocabulary.values.tolist():\n",
    "            p += np.log(df.loc[df[\"Vocabulary\"] == word].ratio.values[0])\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 0.7786629270266833\n"
     ]
    }
   ],
   "source": [
    "#my_tweet = 'She smiled.'\n",
    "my_tweet = all_pos_tweets[0]\n",
    "logprior = np.log(Prob_pos_tweet / Prob_neg_tweet)\n",
    "p = naive_bayes_predict(my_tweet, logprior, freq_dict_info)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tweet(my_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>PosFreq(1)</th>\n",
       "      <th>NegFreq(0)</th>\n",
       "      <th>Prob_pos</th>\n",
       "      <th>Prob_neg</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>smile</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>1.058291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vocabulary PosFreq(1) NegFreq(0)  Prob_pos  Prob_neg     ratio\n",
       "3427      smile         49         46  0.001522  0.001439  1.058291"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict_info.query('Vocabulary == \"smile\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is -0.6975881809149506\n"
     ]
    }
   ],
   "source": [
    "my_tweet = all_neg_tweets[0]\n",
    "logprior = np.log(Prob_pos_tweet / Prob_neg_tweet)\n",
    "p = naive_bayes_predict(my_tweet, logprior, freq_dict_info)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hopeless', 'tmr', ':(']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tweet(my_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>PosFreq(1)</th>\n",
       "      <th>NegFreq(0)</th>\n",
       "      <th>Prob_pos</th>\n",
       "      <th>Prob_neg</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>smile</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>1.058291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vocabulary PosFreq(1) NegFreq(0)  Prob_pos  Prob_neg     ratio\n",
       "3427      smile         49         46  0.001522  0.001439  1.058291"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict_info.query('Vocabulary == \"smile\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def process_tweet_(tweet): \n",
    "    stopwords_ = stopwords.words('english')\n",
    "    # remove stock market ticker\n",
    "    tweet = re.sub(r'\\$\\w*','',tweet)\n",
    "    # remove RT\n",
    "    tweet = re.sub(r'^Rettweet|^(R|r)(T|t)[\\s]+','',tweet)\n",
    "    # remove hyperlink\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtag\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case = False, strip_handles = True, reduce_len = True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    tweets_clean = []\n",
    "    \n",
    "    for word in tweet_tokens:\n",
    "        if word not in stopwords_ and word not in string.punctuation:\n",
    "            stem_word = PorterStemmer().stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "    return ' '.join(tweets_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(preprocessor=process_tweet_)\n",
    "text_count = cv.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(text_count, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57075"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.217"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['ye', 'back', 'window', 'switch', 'lap', 'optim', 'lu'],\n",
       "       dtype='<U29'),\n",
       " array(['thank', 'guy'], dtype='<U29'),\n",
       " array(['love', 'better', 'life', 'lord'], dtype='<U29'),\n",
       " array(['like', 'yeah', 'better', 'use', 'account', 'offici'], dtype='<U29'),\n",
       " array(['night', 'today', 'fun', 'good', 'wish', 'excit', 'ok', 'ugli',\n",
       "        'met', 'tmrw', 'troy'], dtype='<U29'),\n",
       " array(['see', 'later'], dtype='<U29'),\n",
       " array(['dri', 'hot', 'ff', 'scorch', 'summer'], dtype='<U29'),\n",
       " array(['day', 'get', 'text', 'join', 'hushedpinwithsammi', 'event',\n",
       "        'might', 'luv'], dtype='<U29'),\n",
       " array(['bo', 'birmingham', 'oracl', 'samosa'], dtype='<U29'),\n",
       " array(['week', 'song', 'ducktail', 'surreal', 'exposur', 'sotw'],\n",
       "       dtype='<U29')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.inverse_transform(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@Malan_Sanjaya yes switched back :) my lap is optimized for windows 7 Lu :|',\n",
       "       '@mayusushita @dildeewana_ @sonalp2591 @deepti_ahmd @armansushita8 Thanks Guys :)',\n",
       "       'Your love, O Lord, is better than life. :) &lt;3 https://t.co/KPCeYJqKLM',\n",
       "       '@yasminyasir96 yeah but it will be better if we use her official Account :) Like The Other @PracchiNDesai ❤️',\n",
       "       \"Ok good night I wish troye wasn't ugly and I met him today:)():)!:!; but ok today was fun I'm excited for tmrw!!\",\n",
       "       '@ChrisBourne see you later :)',\n",
       "       'Dry, hot, scorching summer #FF :) @infocffm @MediationMK @ExeterMediation @KentFMS @EssexMediation',\n",
       "       'I just joined the #HushedPinWithSammy Event :D Might get to Text with @SammyWilk for a day! Luv U @HushedApp http://t.co/czdow1i44W',\n",
       "       '@MDWidlake @mnorgaard We have BOS, \"Birmingham Oracle Samosas\" at @OracleMidlands :)',\n",
       "       'My Song of the Week is Ducktails - Surreal Exposure #SOTW https://t.co/BeXVWh7zIR Jingly jangly loveliness! :-)'],\n",
       "      dtype='<U152')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:575]",
   "language": "python",
   "name": "conda-env-575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
